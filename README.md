# upstage-ml-regression
House Price Prediction | 아파트 실거래가 예측

# 1. 경진대회 소개

## 1.1. 개요

- AiStages 아파트 실거래가 예측
    
    > 서울시 아파트 실거래가 매매 데이터를 기반으로 아파트 가격을 예측하는 대회
    > 

## 1.2. 일정

- 대회 시작일: 2024.01.15
- 최종 제출 마감 기한: 2024.01.25 19:00

## 1.3. 평가 지표

- 매매 실거래가를 예측하는 Regression 대회로서, 평가지표는 RMSE(Root Mean Squared Error)를 사용한다.

## 1.4. 데이터 설명

- 학습 데이터: (1,118,822, 52)
    - 예측해야 할 거래금액(target)을 포함하여 아파트의 정보에 대한 52개의 변수와 거래시점에 대한 변수가 주어진다.
    - 2007년 1월 1일부터 2023년 6월 30일까지의 거래 데이터로 이루어져 있다.
- 평가 데이터: (9272, 51)
    - 거래금액(target)을 제외한 51개의 변수가 주어진다.
    - 2023년 7월 1일부터 2023년 9월 26일까지의 거래 데이터로 이루어져 있다.

# 2.  경진대회 수행 절차 및 방법

## 2.1. 수행 절차

- Step 1: 유사 경진대회 분석 및 인사이트 도출
- Step 2: EDA
- Step 3: 전처리 - 결측치 처리, 이상치 처리, 인코딩
- Step 4: 피쳐 엔지니어링 - 파생 변수 생성 및 Feature Selection
- Step 5: 모델링 - Validation Set 구축, Hyper-parameter Tuning 및 Ensemble을 통한 성능 실험
- Step 6: 학습된 모델 성능을 기반으로 ML 파이프라인 반복
- Step 7: 최종 제출 파일 선택

## 2.2. 수행 방법

- 매일 팀 미팅을 통해 진행상황 및 아이디어 공유
- Github repository를 사용해 작업 코드 공유
- Slack을 통한 실시간 의견 교류

# 3. 경진대회 수행 과정

## 3.1. EDA

### 3.1.1 주요 변수별 분포 확인

![output.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/665aabc8-73cb-4a4a-bcc8-48cc3d6fce43/a039d093-1320-4872-a5b8-9ab78dcc1908/output.png)

> 주요 수치형 변수의 분포를 히스토그램으로 시각화하여 각 변수의 분포 및 편향 정도를 확인할 수 있었다.
> 
> - 일부 변수의 경우, 0에서 count가 치솟는 것으로 보아 0인 값들이 결측치일 가능성이 있음을 확인했다.
>     - 0의 개수가 10000개 이상인 변수: 'k-전용면적별세대_60', 'k-전용면적별세대_60_85', 'k-전용면적별세대_85_135', '건축면적', '주차대수'
>         - k-전용면적별세대_60, k-전용면적별세대_60_85, k-전용면적별세대_85_135의 경우, 대부분 실제 값이 0인 것으로 보인다.
>         - 반면, 건축면적, 주차대수의 경우, *0이 결측치일 가능성*이 있으며 만약 그렇다면 아파트 단지 정보이므로 해당 아파트의 실제 정보 값으로 대체하는 방법을 고려할 수 있다.

### 3.1.2. 상관관계 분석

![output01.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/665aabc8-73cb-4a4a-bcc8-48cc3d6fce43/6e932c99-ee07-4cbe-86be-2265e2d43428/output01.png)

> 주요 수치형 변수에 대한 Correlation Matrix를 통해 다음과 같은 사실을 파악할 수 있었다.
> 
> - 아파트 단지 관련 변수들(k-전체동수, k-전체세대수, k-연면적, k-주거전용면적, k-관리비부과면적, k-전용면적별세대, 주차대수) 간에 높은 상관관계를 보인다.
>     - 이 변수들은 아파트 단지별로 모두 같은 값을 가지므로 당연한 결과다. 다시 말해, 이 변수들은 ‘*아파트명’ 변수 하나로 대체 가능*하다. 하지만 *평가 데이터에만 존재하는 아파트의 실거래가 예측을 위해 적절한 변수를 선택해야* 한다.
> - target과의 상관관계가 높은 변수는 전용면적, 주차대수, 계약년월, k-연면적, k-주거전용면적, k-관리비부과면적, 좌표Y이다.
>     - 전용면적: 계약된 가구의 전용면적
>     - 주차대수: 아파트 단지 전체의 주차 가능 대수
>     - 계약년월과 양의 상관관계 → 최근일수록 실거래가 높음
>     - k-연면적: 아파트 단지 전체의 연면적, k-주거전용면적과의 상관계수 0.90
>     - k-주거전용면적: 아파트 단지 전체 전용면적 = SUM(전용면적별세대수 x 전용면적)
>     - k-관리비부과면적: k-주거전용면적 or k-연면적
>     - 좌표Y(위도)와 음의 상관관계 → 남쪽으로 갈수록 실거래가 높음

## 3.2. Preprocessing

### 3.2.1. 결측치 처리

![output02.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/665aabc8-73cb-4a4a-bcc8-48cc3d6fce43/44ab0225-def9-4372-bb2f-394bf9b771d3/output02.png)

> 아파트 단지 관련 변수 중 일부 변수의 결측치는 서울시 공동주택 아파트 정보(https://data.seoul.go.kr/dataList/OA-15818/A/1/datasetView.do )를 사용해 대체할 수 있었다.
> 
> - 나머지 결측치 처리 방법
>     - 결측치가 50만개 이상인 변수
>         - '주차대수'를 제외하고 결측치가 50만개 이상인 모든 변수를 제거하였다.
>     - 그 외 수치형 변수
>         - '주차대수': Baseline에서 사용한 *선형 보간법은 데이터의 특성상 적절하지 않은 방법*이라고 판단하여, *회귀 모델(RandomForestRegressor)을 사용해 해당 변수를 Target으로 하여 예측을 수행하고 예측값으로 결측치를 대체*하였다.
>         - ‘좌표X’, ‘좌표Y’: geopy 라이브러리를 사용해 도로명 주소를 좌표로 변환하여 결측치를 채워주었다.
>     - 그 외 범주형 변수
>         - 'NULL'이라는 임의의 범주로 대체하였다.

### 3.2.2. 이상치 처리

- ‘전용면적’을 기준으로 IQR 기반 이상치를 포함한 데이터를 제거했을 경우, Validation Set의 예측값 분석 결과 높은 실거래가의 데이터에 대한 예측력이 이상치를 제거하지 않았을 때보다 떨어지는 것을 확인하였다.
    - 이를 통해 *전용면적이 매우 큰(높은 확률로 실거래가가 매우 높은) 데이터를 이상치로 판단하는 것은 적절하지 않다는 결론*을 내릴 수 있었다.
- 일반적인 패턴을 벗어나는 실거래가를 지닌 데이터가 모델의 일반화 성능을 저하시킬 가능성이 있기 때문에 ‘target’을 기준으로 IQR 기반 이상치를 제거해보았다.
    - 높은 가격대의 데이터가 사라지면서 Validation RMSE가 감소할 수밖에 없기 때문에 해당 이상치 제거가 실제로 성능 향상에 유효한지 판단할 수 없었다.
    - 또한, target은 right-skewed 분포를 보이기 때문에 IQR 방식으로 이상치를 판단할 경우에 적용되는 상한선이 적절하지 않을 수 있어 그 결과 *높은 실거래가를 지닌 데이터에 대한 패턴을 학습하는 데 중요한 데이터를 제거하게 될 수 있으므로* 위험한 선택일 수 있다.

### 3.2.3. 범주형 변수 인코딩

- 타겟 인코딩
    - 일부 범주형 변수(도로명, 도로, 동)에 대해 실거래가 평균 기준 순위로 인코딩하였다.
        - ‘도로명’ → '도로명_실거래가순위',
        - ‘도로’ → '도로_실거래가순위'
        - ‘동’ → '동_실거래가순위'
    
    > baseline과 같이 범주형 변수에 대해 *레이블 인코딩을 적용할 경우에 범주 간의 관계를 나타내지 못하며 모델은 학습 시 해당 변수의 값 사이에 순서가 있다고 인식*할 수 있으므로, 임의의 정수를 부여하기보다는 *모델이 범주형 변수의 패턴을 쉽게 학습할 수 있도록 타겟 인코딩 방식을 선택*했다.  
    * 또한, 단순히 데이터에 대한 타겟 변수의 평균으로 인코딩하지 않고 *각 범주의 순위값으로 인코딩하여 범주 간의 순서를 모델에 반영*하고자 했다.
    > 

### 3.2.4. 업샘플링

- 모델 학습 후 Validation 예측값 분석을 통해 주로 실거래가가 높은 데이터의 예측값이 높은 Squared Error를 보인다는 것을 파악하였다. 데이터 불균형으로 인해 *실거래가가 높은 데이터가 underfit되었다고 판단하여 실거래가가 높은(100억 이상인) 데이터의 개수를 늘리는 업샘플링*을 시도했다.

## 3.3 Feature Engineering

### 3.3.1. 파생변수 생성

- 시군구 컬럼을 '구'와 ‘동'으로 분할
- '계약년월'을 '계약년', '계약월'로 분할
- '도로명'(전체 도로명 주소)에서 '도로'(도로 이름, 예: 삼성로)만 추출
- '부촌여부' 변수 추가
    - 실거래라 상위 아파트가 많이 위치한 동(청담동, 한남동, 성수동 1가) 여부
- '상위아파트여부' 변수 추가
    - 실거래가 top10 아파트 여부
- '대장아파트거리' 변수 추가
    - 지역구별 대장 아파트와의 거리
- 'top아파트거리' 변수 추가
    - 상위 아파트와 같은 동에 속하는 데이터 한정, 해당 동별 상위 아파트와의 거리
- '건물연식' 변수 추가
    - ‘계약년’ - ‘건축년도’로 계산
- '브랜드명' 변수 추가
    - '아파트명'이 주요 브랜드명을 포함하는 경우 해당 브랜드명 입력
- '인근지하철역개수' 변수 추가
    - 주어진 subway_feature 데이터의 좌표 변수를 이용해 아파트 좌표와의 haversine distance를 구하여 인근 500m 내에 위치한 지하철역의 개수 계산
- '인근버스정류장개수' 변수 추가
    - 주어진 bus_feature 데이터의 좌표 변수를 이용해 아파트 좌표와의 haversine distance를 구하여 인근 버스정류장역 개수 계산
- 그 외 외부 데이터를 사용한 파생변수
    - '기준금리', '전세가격지수', '인구밀도', '인근공원개수', '인근종합병원개수', '인근학교개수', '한강지천생활지수’ 등

### 3.3.2. Feature Selection

- 주어진 변수들 중 필요 없다고 판단되는 변수, A/B Test 결과 성능 향상에 도움이 되지 않는 변수, 모델 학습 결과 중요도가 낮은 변수를 제거하고 아래의 20개 변수만 사용하였다.
    - '도로명', '전용면적', 'k-복도유형', 'k-단지분류', '계약년', '계약월', '동', '좌표X', '좌표Y', '건축년도', '부촌여부', '상위아파트여부', '대장아파트거리', '도로 ', '구', '주차대수', '인근지하철역개수', '브랜드명', '건물연식', 'top아파트거리'
    - Feature Importances
    
    ![feature_imp.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/665aabc8-73cb-4a4a-bcc8-48cc3d6fce43/97207463-eb17-4f84-aec6-099458b92064/feature_imp.png)
    

## 3.4. Modeling

### 3.4.1. 모델 선택 및 튜닝

- 여러 모델로 학습을 진행한 뒤 가장 성능이 좋았던 LGBMRegressor를 선택했다.
- Optuna를 사용해 최적의 파라미터 조합을 찾아 성능을 평가하였고, 이후 직접 값을 변경해가며 가장 좋은 성능을 보이는 값으로 설정하였다.

### 3.4.2. 검증

- 초기에는 K-fold Cross Validation으로 Out-of-fold 예측값을 구하여 학습 성능을 검증하였다.
- 이후 Test Dataset이 Training Dataset보다 미래의 데이터로 이루어져 있는 특성을 반영한 신뢰할 수 있는 Validation Set 구축의 필요성을 절감하여 *'계약년월일'을 기준으로 최근 20%의 거래 데이터를 Validation Set으로 추출*하였다.
    - 팀원들 간에 Validation Set을 통일하여 동일한 데이터에 대해 서로의 모델 성능을 비교 가능하도록 하였다.

# 4. 경진대회 결과

## 4.1. 리더보드 순위

- Public 리더보드
    - 1위, RMSE: 14426.4378

![스크린샷 2024-01-30 오후 6.40.00.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/665aabc8-73cb-4a4a-bcc8-48cc3d6fce43/4ca115d2-328f-4994-b578-eb460907874b/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2024-01-30_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_6.40.00.png)

- Private(최종) 리더보드
    - 1위, RMSE: 10721.2559

![스크린샷 2024-01-30 오후 6.40.15.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/665aabc8-73cb-4a4a-bcc8-48cc3d6fce43/e1aeae68-8814-45b8-b78a-a7b364769c84/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2024-01-30_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_6.40.15.png)

## 4.2. 결과 분석

- 좋은 순위를 기록할 수 있었던 이유를 분석해보았다.
    1. 리더보드 스코어를 신뢰하지 않은 것
        - 대회 첫날부터 Validation 스코어와 리더보드 스코어 간에 상당한 차이가 발생하는 것에 의문이 들었다. 가능한 요인으로는 1) 훈련 *데이터셋에의 Overfitting, 2) 데이터의 특성을 충분히 반영하지 못하는 Validation Set, 3) 평가 데이터셋의 불균형한 분포*가 있을 수 있다고 추론하였다.
            - 그러나 Validation Set 재설정 및 Cross-Validation 방식을 사용해도 리더보드 스코어에 가까워지지 않는 점, 모든 조가 동일한 현상을 겪고 있는 점으로 미루어볼 때 *평가 데이터셋 자체의 오류 혹은 이해할 수 없을 정도로 독특한 분포 때문*이라고 결론내릴 수 있었다.
            
            > 따라서 우리 조는 *리더보드 스코어를 신뢰할 수 없다고 판단*하였고, *Validation 스코어를 기준으로 성능을 평가*하기로 하였다. 또한 최종 제출 파일도 Validation 스코어가 가장 잘 나온 파일을 선택하였다.
            > 
    2. 결측치 처리와 피쳐 엔지니어링에 집중한 것
        - 다수의 변수에서 데이터의 80퍼센트가 넘는 결측치가 있었고, 단순히 해당 변수를 제거하거나 보간하기보다는 유의미하다고 판단되는 변수에 한해서 결측치를 최대한 실제 값으로 채워 약 20퍼센트에서 최대 0퍼센트까지 줄이는 작업을 거쳤다.
        - 피쳐 엔지니어링 시 무조건 많은 외부 데이터를 이용하거나 파생 변수를 생성하는 대신, 주어진 데이터를 고려하여 성능 향상에 도움이 될 수 있는 요소를 잘 파악하고자 했다.
            - 학습 데이터는 2023년 7월 기준 지난 15년 간의 아파트 거래 내역이고 평가 데이터는 이후 3개월 간의 거래 내역임을 고려할 때, 평가 데이터에 속하는 대부분의 거래는 훈련 데이터에 이미 존재하는 아파트의 거래일 것이다. 결국 훈련데이터에 존재하는 아파트에 대한 예측에 한해 아파트를 구분하는 범주형 변수 외에 아파트 단지에 따라 동일한 값을 가지는 변수들은 불필요해진다. 이는 *아파트를 구분하는 변수인 ‘아파트명’ 혹은 ‘도로명’과 ‘계약년’만으로 해당 아파트의 년도별 실거래가 분포를 학습함으로써 어느정도 높은 예측 성능을 보여줄 수 있음*을 뜻한다.
            
            > 따라서 아파트를 구분하는 변수인 ‘도로명’(도로명 주소)과 ‘아파트명’ 변수 중 결측치가 없는 ‘도로명’ 변수 및 파생변수인 ‘도로’, ‘동’ 변수를 타겟 인코딩하여 해당 변수의 범주 간 패턴을 모델이 더 잘 학습하도록 했다.
            > 
        - 평가 데이터에 존재하지 않거나 평가 데이터의 기간 내 충분한 횟수의 거래가 이루어지지 않은 아파트의 경우, ‘도로명’, ‘계약년’ 외에 실거래가에 영향을 주는 적절한 변수를 통해 학습되어져야 한다.
            
            > 위치에 따른 실거래가 분포를 학습하기에 유의미한 위/경도 정보인 ‘좌표X’, ‘좌표Y’의 결측치를 모두 채워준 것이 성능 향상에 도움이 된 것으로 보이며, ‘주차대수’, ‘건축년도’, ‘건물연식’, ‘복도유형’과 같은 아파트 단지 관련 변수 외에 500m 이내 지하철역 개수 및 구/동별 실거래가가 높은 대표 아파트와의 거리를 나타내는 파생변수도 유의미한 역할을 한 것으로 보인다.
            > 
    3. 높은 실거래가에 대한 예측력 향상에 신경쓴 것
        - RMSE의 특성상 높은 실거래가를 잘 예측할수록 유리하다. 또한 현재 모델이 높은 실거래가에 대한 예측력이 떨어지므로, 그 원인을 찾아 처리를 해주는 것이 필요해 보였다.
            - 훈련 데이터의 Target 분포에서 알 수 있듯이 실거래가가 높은 데이터의 수가 현저히 적다. 이러한 데이터 불균형을 해소한다면 높은 실거래가에 대한 예측력이 향상될 것이라고 생각했다.
            
            > 따라서 100억이 넘는 데이터를 복제하여 훈련데이터에 포함시키는 방식을 사용했다. 중복 데이터를 추가할 경우에는 해당 데이터에 대해 오버피팅이 일어날 수 있지만 적절히 추가한다면 오히려 언더피팅을 개선하는 효과를 얻을 수 있을 것이라 판단했다.
            > 
            - 높은 실거래가를 지닌 데이터를 분류할 수 있도록 ‘부촌여부’, ‘상위아파트여부’와 같은 이진 변수를 추가했다.

# 5. 개인 회고

## **5.1 학습 목표를 달성하기 위해 무엇을 어떻게 했는가?**

- 개인적 목표
    - 대회 순위를 높이기 위해 복잡한 모델을 만들거나 여러 모델을 앙상블하기보다는 좋은 모델, 효율적인 모델을 구축하는 것이었다. 물론 그런 모델을 구축하고나서 최후 스코어 향상을 위해 여러 모델링 방식을 시도해봐야겠다고 생각했지만 짧은 대회 일정상 그 단계로 넘어가지 못하고 마무리해야 했다.
- 목표 달성을 위해 다음과 같은 노력을 했다.
    1. 효츌적인 모델 구축을 위해 EDA 및 데이터 전처리, 피쳐 엔지니어링이 중요하다고 생각했기에 해당 단계에 가장 많은 시간을 투자하였다.
    2. 리더보드 스코어를 신뢰할 수 없었기 때문에 신뢰할 수 있는 Validation Set을 구축하기 위해 K-fold CV 및 최근데이터를 hold-out 방식을 분할하는 방식을 사용했으며 검증 스코어를 토대로 피쳐를 선택하고 모델을 튜닝하였다.
    3. 데이터 특성에 맞는 결측치 처리 및 효과적인 범주형 변수 인코딩 방식을 적용하기 위해 온라인 강의를 통해 학습한 모델 기반 회귀 대체 방식 및 타겟 인코딩 방식을 사용하였다. 

## **5.2. 전과 비교하여 새롭게 시도한 변화는 무엇이고, 어떤 효과가 있었는가?**

- 이전 머신러닝 프로젝트의 경우, 머신러닝 워크플로우를 경험하고 케글 대회에 입문하는 것에 의미를 두고 진행했었기 때문에 공유된 코드를 분석하고 이미 짜여진 코드를 기반으로 피쳐 엔지니어링 및 모델링 부분에서 추가 아이디어를 도출하고 구현하기를 반복하면서 리더보드 스코어가 어떻게 변화하는지 관찰하는 데 집중했었다.
- 반면, 이번 프로젝트에서는 머신러닝 프로세스의 전과정을 순서대로 수행하면서 데이터를 잘 이해하고 적절한 방식으로 전처리하며, 유의미한 파생변수를 직접 고안하며, 신뢰할 수 있는 Validation Set을 구축하며, 문제를 정의하고 해결하는 모든 과정을 경험할 수 있었다. 이러한 경험을 통해 전체적인 머신러닝 프로세스를 체계적으로 이해하고 실전에서의 문제 해결 경험을 쌓을 수 있었다.

## **5.3. 마주한 한계는 무엇이며, 아쉬웠던 점은?**

- ‘실거래가’라는 타겟이 훈련 데이터에서 드러나지 않는 불규칙한 패턴을 가질 수 있는 미래의 정보이다보니 평가데이터셋이 그런 불규칙한 패턴을 포함할 경우에 예측에 어느정도 한계가 있을 수밖에 없다. 특히 Public 리더보드 점수에 오류가 있어 굉장히 높은 RMSE가 산출되었는데 오류 가능성보다는 평가 데이터셋의 이상치 또는 비정상적인 편향 가능성에 무게를 두었고. 때문에 평가데이터의 이상치 혹은 편향에 어떻게 대처할 수 있는지 고민해보게 되었다.
    - 예를 들어, 1) 특정 아파트의 실거래가가 짧은 기간 사이에 갑자기 폭등하거나 폭락하는 경우, 2) 일반적인 시세보다 비싸게 혹은 싸게 거래되는 경우, 3) 같은 아파트 내에서 프리미엄(예: 한강뷰)에 따른 가격 차이가 심한 경우, 4) 같은 단지 내 동별로 가격 차이가 심한 경우가 있을 수 있다. 3, 4번의 경우에는 거래된 동 정보 및 아파트 내 동별 특징에 관한 데이터를 수집하여 관련 변수를 추가할 수 있다면 해결할 수 있을 것이다.
- 그 외에 시계열 데이터의 특성을 이용한 접근 방식, 보다 효과적인 업샘플링 방식, 실거래가 구간별 분할 학습, 모델 앙상블 등을 생각해보았으나 시간상 구현해보지 못한 것이 아쉽다.

## **5.4. 한계/교훈을 바탕으로 다음 경진대회에서 새롭게 시도해볼 것은?**

- 다음 경진대회는 경험이 없는 CV 관련 딥러닝 경진대회이기 때문에 새로운 시도를 계획하기보다는 이미지 처리에 관련한 도메인 사전 지식을 쌓고  딥러닝 모델에 대한 개념 및 구조를 부지런히 학습한 다음 대회에 참여하는 것이 중요할 것이다. 단, 이전 프로젝트에서의 한계를 고찰해보면 데이터의 특성, 모델 선택, 그리고 검증 데이터의 중요성이 두드러졌으며 Validation 스코어 및 리더보드 스코어 간의 신뢰도 파악과 그에 따른 전략을 마련하는 것도 중요하다는 교훈을 얻을 수 있다.
